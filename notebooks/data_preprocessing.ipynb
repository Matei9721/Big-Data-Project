{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/15 11:14:15 WARN Utils: Your hostname, MacBook-Air-di-Emanuele.local resolves to a loopback address: 127.0.0.1; using 10.0.0.197 instead (on interface en0)\n",
      "23/03/15 11:14:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/15 11:14:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Import PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create SparkSession\n",
    "spark = SparkSession.builder.appName('MyApp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading the training csv.\n",
    "\"\"\"\n",
    "\n",
    "training = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/imdb/train_movies_extra_data_new.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the validation csv.\n",
    "\"\"\"\n",
    "\n",
    "validation = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/imdb/validation_extra_data.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the test csv.\n",
    "\"\"\"\n",
    "\n",
    "test = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/imdb/test_extra_data.csv', header=True,\n",
    "    inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf, when, split, regexp_replace, min, explode\n",
    "from pyspark.sql.types import BooleanType, IntegerType\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "import re\n",
    "\n",
    "def manage_awards(award):\n",
    "\n",
    "    if award is not None:\n",
    "        if re.search('win', award) or re.search('wins', award) or re.search('won', award):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "my_udf = udf(manage_awards, IntegerType())\n",
    "\n",
    "def preprocessing_method(df):\n",
    "\n",
    "    \"\"\"\n",
    "    This method will convert to integer all the years and will put to categorical weather\n",
    "    a movie won any awards or not.\n",
    "    :param df: dataframe\n",
    "    :return: return a preprocessed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Here casting to integer all the numerical values\n",
    "    \"\"\"\n",
    "    df = df.withColumn('startYear', col('startYear').cast('int'))\n",
    "    df = df.withColumn('endYear', col('endYear').cast('int'))\n",
    "    df = df.withColumn('numVotes', col('numVotes').cast('int'))\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess boxoffice, and put the lowest value if it is null.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.withColumn(\"boxoffice\", regexp_replace(col(\"boxoffice\"), \"[$,]\", \"\").cast(\"int\"))\n",
    "    min_boxoffice = df.agg(min('boxoffice')).collect()[0][0]\n",
    "    df = df.withColumn(\"boxoffice\", when(col(\"boxoffice\").isNull(), min_boxoffice).otherwise(col(\"boxoffice\")))\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the imdb votes.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.withColumn('imdb_votes', regexp_replace(col('imdb_votes'), \"[,]\", \"\").cast('int'))\n",
    "\n",
    "    \"\"\"\n",
    "    Awards transformed into True or False\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.withColumn('awards', my_udf(df['awards']))\n",
    "\n",
    "    \"\"\"\n",
    "    Substitute numVotes value when null with the value of imdb votes\n",
    "    \"\"\"\n",
    "\n",
    "    # scaling part\n",
    "\n",
    "    \"\"\"\n",
    "    df = df.withColumn('numVotes', when(col('numVotes').isNull(), col('imdb_votes')).\n",
    "                       otherwise(col('numVotes')))\n",
    "    df = df.withColumn('startYear', when(col('startYear').isNull(), col('imdb_year')).\n",
    "                       otherwise(col('startYear')))\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Transformations from string to lists.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.withColumn('country', split(col('country'), ','))\n",
    "    df = df.withColumn('genre', split(col('genre'), ','))\n",
    "    df = df.withColumn('actors', split(col('actors'), ','))\n",
    "    df = df.withColumn('language', split(col('language'), ','))\n",
    "\n",
    "    df_exploded = df.select('*', explode('actors').alias('my_value'))\n",
    "\n",
    "    unique_values = [str(row[0]) for row in df_exploded.select(explode('my_value')).distinct().collect()]\n",
    "    df_pivoted = df_exploded.groupBy('id').pivot('my_value', unique_values).agg(when(col('my_value').isNotNull(), 1).otherwise(0))\n",
    "\n",
    "    # join the pivoted dataframe with the original dataframe\n",
    "    df = df.join(df_pivoted, 'id', 'left_outer')\n",
    "\n",
    "    \"\"\"\n",
    "    Dropping the columns.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.drop('_c0', 'primaryTitle', 'originalTitle', 'endYear', 'plot', 'language', 'rating', 'entry_type', 'production', 'imdb_votes', 'imdb_year')\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'explode(my_value)' due to data type mismatch: input to function explode should be array or map type, not string;\n'Project [explode(my_value#3792) AS List()]\n+- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#3725, plot#27, actors#3747, language#3769, country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37, my_value#3792]\n   +- Generate explode(actors#3747), false, [my_value#3792]\n      +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#3725, plot#27, actors#3747, split(language#29, ,, -1) AS language#3769, country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n         +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#3725, plot#27, split(actors#28, ,, -1) AS actors#3747, language#29, country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n            +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, split(genre#26, ,, -1) AS genre#3725, plot#27, actors#28, language#29, country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n               +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, split(country#30, ,, -1) AS country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n                  +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, manage_awards(awards#31)#3680 AS awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n                     +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, boxoffice#3636, rating#33, entry_type#34, production#35, cast(regexp_replace(imdb_votes#36, [,], , 1) as int) AS imdb_votes#3658, imdb_year#37]\n                        +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, CASE WHEN isnull(boxoffice#3585) THEN 147 ELSE boxoffice#3585 END AS boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                           +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, cast(regexp_replace(boxoffice#32, [$,], , 1) as int) AS boxoffice#3585, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                              +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, cast(numVotes#24 as int) AS numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, boxoffice#32, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                                 +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, cast(endYear#22 as int) AS endYear#3541, runtimeMinutes#23, numVotes#24, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, boxoffice#32, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                                    +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, cast(startYear#21 as int) AS startYear#3519, endYear#22, runtimeMinutes#23, numVotes#24, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, boxoffice#32, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                                       +- Relation [_c0#17,tconst#18,primaryTitle#19,originalTitle#20,startYear#21,endYear#22,runtimeMinutes#23,numVotes#24,label#25,genre#26,plot#27,actors#28,language#29,country#30,awards#31,boxoffice#32,rating#33,entry_type#34,production#35,imdb_votes#36,imdb_year#37] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [39]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03mPreprocessing the training dataset.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m training_prep \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocessing_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [38]\u001B[0m, in \u001B[0;36mpreprocessing_method\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     75\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m'\u001B[39m, split(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     77\u001B[0m df_exploded \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m, explode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactors\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmy_value\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m---> 79\u001B[0m unique_values \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mstr\u001B[39m(row[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdf_exploded\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexplode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmy_value\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdistinct()\u001B[38;5;241m.\u001B[39mcollect()]\n\u001B[1;32m     80\u001B[0m df_pivoted \u001B[38;5;241m=\u001B[39m df_exploded\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mpivot(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmy_value\u001B[39m\u001B[38;5;124m'\u001B[39m, unique_values)\u001B[38;5;241m.\u001B[39magg(when(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmy_value\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39misNotNull(), \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39motherwise(\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m     82\u001B[0m \u001B[38;5;66;03m# join the pivoted dataframe with the original dataframe\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2023\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m   2002\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   2003\u001B[0m     \u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   2004\u001B[0m \n\u001B[1;32m   2005\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2021\u001B[0m \u001B[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001B[39;00m\n\u001B[1;32m   2022\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2023\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2024\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    192\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: cannot resolve 'explode(my_value)' due to data type mismatch: input to function explode should be array or map type, not string;\n'Project [explode(my_value#3792) AS List()]\n+- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#3725, plot#27, actors#3747, language#3769, country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37, my_value#3792]\n   +- Generate explode(actors#3747), false, [my_value#3792]\n      +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#3725, plot#27, actors#3747, split(language#29, ,, -1) AS language#3769, country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n         +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#3725, plot#27, split(actors#28, ,, -1) AS actors#3747, language#29, country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n            +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, split(genre#26, ,, -1) AS genre#3725, plot#27, actors#28, language#29, country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n               +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, split(country#30, ,, -1) AS country#3703, awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n                  +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, manage_awards(awards#31)#3680 AS awards#3681, boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#3658, imdb_year#37]\n                     +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, boxoffice#3636, rating#33, entry_type#34, production#35, cast(regexp_replace(imdb_votes#36, [,], , 1) as int) AS imdb_votes#3658, imdb_year#37]\n                        +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, CASE WHEN isnull(boxoffice#3585) THEN 147 ELSE boxoffice#3585 END AS boxoffice#3636, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                           +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, cast(regexp_replace(boxoffice#32, [$,], , 1) as int) AS boxoffice#3585, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                              +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, endYear#3541, runtimeMinutes#23, cast(numVotes#24 as int) AS numVotes#3563, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, boxoffice#32, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                                 +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, startYear#3519, cast(endYear#22 as int) AS endYear#3541, runtimeMinutes#23, numVotes#24, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, boxoffice#32, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                                    +- Project [_c0#17, tconst#18, primaryTitle#19, originalTitle#20, cast(startYear#21 as int) AS startYear#3519, endYear#22, runtimeMinutes#23, numVotes#24, label#25, genre#26, plot#27, actors#28, language#29, country#30, awards#31, boxoffice#32, rating#33, entry_type#34, production#35, imdb_votes#36, imdb_year#37]\n                                       +- Relation [_c0#17,tconst#18,primaryTitle#19,originalTitle#20,startYear#21,endYear#22,runtimeMinutes#23,numVotes#24,label#25,genre#26,plot#27,actors#28,language#29,country#30,awards#31,boxoffice#32,rating#33,entry_type#34,production#35,imdb_votes#36,imdb_year#37] csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preprocessing the training dataset.\n",
    "\"\"\"\n",
    "\n",
    "training_prep = preprocessing_method(training)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocessing the validation dataset.\n",
    "\"\"\"\n",
    "\n",
    "validation_prep = preprocessing_method(validation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocessing the test dataset.\n",
    "\"\"\"\n",
    "\n",
    "test_prep = preprocessing_method(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Saving to csv the training dataset.\n",
    "\"\"\"\n",
    "\n",
    "training_prep.toPandas().to_csv('../datasets/models_dataset/train.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving to csv the validation dataset.\n",
    "\"\"\"\n",
    "\n",
    "validation_prep.toPandas().to_csv('../datasets/models_dataset/validation.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving to csv the test dataset.\n",
    "\"\"\"\n",
    "\n",
    "test_prep.toPandas().to_csv('../datasets/models_dataset/test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}