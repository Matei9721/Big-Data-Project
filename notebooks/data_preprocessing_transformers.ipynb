{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create SparkSession\n",
    "spark = SparkSession.builder.appName('MyApp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the training csv.\n",
    "\"\"\"\n",
    "\n",
    "training = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/final/train_plots_awards_genre_no_duplicates.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the validation csv.\n",
    "\"\"\"\n",
    "\n",
    "validation = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/final/validation_plots_awards_genre_no_duplicates.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the test csv.\n",
    "\"\"\"\n",
    "\n",
    "test = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/final/test_plots_awards_genre_no_duplicates.csv',\n",
    "    header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Transformer\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.sql.functions import col, when, lower, mean, udf, split, regexp_replace, \\\n",
    "    min, array_contains\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "ranges = ('1915-1929', '1930-1939', '1940-1949', '1950-1959', '1960-1969', '1970-1979', '1980-1989',\n",
    "              '1990-1999', '2000-2009', '2010-2019', '2020-2023')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "scalar_udf = udf(lambda arr: float(arr[0]), DoubleType())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "class LowerCaseTransformer(Transformer):\n",
    "    def __init__(self, input_cols=None, output_cols=None):\n",
    "        super(LowerCaseTransformer, self).__init__()\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def _transform(self, df):\n",
    "        df = df.withColumn(self.output_cols[0], lower(self.input_cols[0]))\n",
    "        df = df.withColumn(self.output_cols[1], lower(self.input_cols[1]))\n",
    "        df = df.withColumn(self.output_cols[2], lower(self.input_cols[2]))\n",
    "\n",
    "        return df\n",
    "\n",
    "class CastToInt(Transformer):\n",
    "    def __init__(self, input_cols=None, output_cols=None):\n",
    "        super(CastToInt, self).__init__()\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def _transform(self, df):\n",
    "        df = df.withColumn(self.output_cols[0], col(self.input_cols[0]).cast('int'))\n",
    "        df = df.withColumn(self.output_cols[1], col(self.input_cols[1]).cast('int'))\n",
    "        df = df.withColumn(self.output_cols[2], col(self.input_cols[2]).cast('int'))\n",
    "        df = df.withColumn(self.output_cols[3], col(self.input_cols[3]).cast('int'))\n",
    "\n",
    "        return df\n",
    "\n",
    "class PreprocessYears(Transformer):\n",
    "    def __init__(self, input_col=None, output_col=None, ranges=None):\n",
    "        super(PreprocessYears, self).__init__()\n",
    "        self.input_col = input_col\n",
    "        self.output_col = output_col\n",
    "        self.ranges = ranges\n",
    "\n",
    "    def _transform(self, df):\n",
    "\n",
    "        for r in self.ranges:\n",
    "            limit0, limit1 = r.split('-')\n",
    "            limit0 = int(limit0)\n",
    "            limit1 = int(limit1)\n",
    "            df = df.withColumn(r, when((col('startYear') >= limit0) & (col('startYear') <= limit1), 1).otherwise(0))\n",
    "\n",
    "        return df\n",
    "\n",
    "class PrepRuntimeMin(Transformer):\n",
    "    def __init__(self, input_col=None, output_col=None):\n",
    "        super(PrepRuntimeMin, self).__init__()\n",
    "        self.input_col = input_col\n",
    "        self.output_col = output_col\n",
    "\n",
    "    def _transform(self, df):\n",
    "        mean_runtime = df.select(mean(self.input_col).cast(\"int\")).collect()[0][0]\n",
    "        df = df.withColumn(self.input_col, when(col(self.input_col).isNull(), mean_runtime).\n",
    "                       otherwise(col(self.input_col)))\n",
    "\n",
    "        return df\n",
    "\n",
    "class PrepNumVotes(Transformer):\n",
    "    def __init__(self, input_col=None, output_col=None):\n",
    "        super(PrepNumVotes, self).__init__()\n",
    "        self.input_col = input_col\n",
    "        self.output_col = output_col\n",
    "\n",
    "    def __scaling_method(self, df, column_name, vector_column_name, scaled_column_name, placeholder):\n",
    "        # Replace null values with a placeholder value, e.g. -1, using when/otherwise\n",
    "        df = df.withColumn(column_name, when(col(column_name).isNull(), placeholder).otherwise(col(column_name)))\n",
    "\n",
    "        # Create a VectorAssembler to convert the scalar column to a vector column\n",
    "        assembler = VectorAssembler(inputCols=[column_name], outputCol=vector_column_name)\n",
    "        df = assembler.transform(df)\n",
    "\n",
    "        # Create the StandardScaler transformer and fit it to the data\n",
    "        scaler = StandardScaler(inputCol=vector_column_name, outputCol=scaled_column_name, withMean=True, withStd=True)\n",
    "        scaler_model = scaler.fit(df)\n",
    "\n",
    "        scaled_data = scaler_model.transform(df)\n",
    "\n",
    "        # Replace the placeholder values with null\n",
    "        scaled_data = scaled_data.withColumn(scaled_column_name, when(col(column_name) == -1, None).\n",
    "                                             otherwise(col(scaled_column_name)))\n",
    "        scaled_data = scaled_data.withColumn(column_name, when(col(column_name) == -1, None).\n",
    "                                             otherwise(col(column_name)))\n",
    "\n",
    "        scaled_data = scaled_data.drop(vector_column_name)\n",
    "\n",
    "        return scaled_data\n",
    "\n",
    "    def _transform(self, df):\n",
    "         min_votes = df.select(min(self.input_col)).collect()[0][0]\n",
    "         df = df.withColumn(self.input_col, when(col(self.input_col).isNull(), min_votes).\n",
    "                       otherwise(col(self.input_col)))\n",
    "         df = self.__scaling_method(df, self.input_col, \"vector_column_votes\", \"scaled_votes\", -1)\n",
    "         df = df.withColumn(self.input_col, scalar_udf(df['scaled_votes']))\n",
    "\n",
    "         return df\n",
    "\n",
    "class PrepGenre(Transformer):\n",
    "    def __init__(self):\n",
    "        super(PrepGenre, self).__init__()\n",
    "\n",
    "    def __genre_preprocess(self, df):\n",
    "        # Everything to lower case\n",
    "        df = df.withColumn('Genre', lower(col('Genre')))\n",
    "\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'film ', ''))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), ' in ', ' '))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), ' of ', ' '))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), '\\.', ''))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'drama based on the novel by russell banks;', 'drama'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'drama adapted from wajdi mouawad\\'s play of the same name', 'drama'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'world war ii', 'war'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'biopic', 'biography'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'drama\\[not in citation given\\]', 'drama'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'kung fu', 'kungfu'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'historical romance based on colm tÃ³ibÃ­n\\'s novel of the same name', 'romantic'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), '3-d', '3d'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'neo-noir', 'noir'))\n",
    "        df = df.withColumn('Genre', when(col('Genre').isNull(), 'unknown').otherwise(col('Genre')))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), '/', ', '))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), ' ,', ','))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), ', ', ','))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), '-', ' '))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'sci fi', 'sci-fi'))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), ' ', ','))\n",
    "        df = df.withColumn('Genre', regexp_replace(col('Genre'), 'martial,arts', 'martial arts'))\n",
    "\n",
    "        # Split the columns\n",
    "        df = df.withColumn('Genre', split(lower(col('Genre')), ','))\n",
    "\n",
    "        # Creating the one hot encoding\n",
    "        unique_values = [str(row[0]) for row in df.selectExpr(\"explode(array_distinct(Genre))\").distinct().collect()]\n",
    "        for value in unique_values:\n",
    "            df = df.withColumn(value, array_contains('Genre', value).cast('int'))\n",
    "\n",
    "        df = df.drop('&', ' ', 'on', 'sf', 'i', 'jidaigeki', '', 'the', 'mouawad\\'s', 'tÃ³ibÃ­n\\'s', 'drama[not', 'given]', 'wajdi')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _transform(self, df):\n",
    "         df = self.__genre_preprocess(df)\n",
    "         return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of the pipeline\n",
    "\"\"\"\n",
    "\n",
    "lowercase = LowerCaseTransformer(input_cols=[\"primaryTitle\", \"originalTitle\", \"plot\"],\n",
    "                                 output_cols=[\"primaryTitle\", \"originalTitle\", \"plot\"])\n",
    "integer = CastToInt(input_cols=[\"startYear\", \"endYear\", \"numVotes\", \"runtimeMinutes\"],\n",
    "                    output_cols=[\"startYear\", \"endYear\", \"numVotes\", \"runtimeMinutes\"])\n",
    "year = PreprocessYears(input_col=\"startYear\", output_col=\"startYear\", ranges=ranges)\n",
    "runtime = PrepRuntimeMin(input_col=\"runtimeMinutes\", output_col=\"runtimeMinutes\")\n",
    "votes = PrepNumVotes(input_col=\"numVotes\", output_col=\"numVotes\")\n",
    "genre = PrepGenre()\n",
    "\n",
    "pipeline = Pipeline(stages=[lowercase, integer, year, runtime, votes, genre])\n",
    "\n",
    "model = pipeline.fit(training)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "training_prep = model.transform(training)\n",
    "training_prep = training_prep.drop('originalTitle', 'endYear', 'scaled_votes', 'Genre')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "training_prep.toPandas().to_csv('train_transform.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "validation_prep = model.transform(validation)\n",
    "validation_prep = validation_prep.drop('originalTitle', 'endYear', 'scaled_votes', 'Genre')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "validation_prep.toPandas().to_csv('validation_transform.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "test_prep = model.transform(test)\n",
    "test_prep = test_prep.drop('originalTitle', 'endYear', 'scaled_votes', 'Genre')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "test_prep.toPandas().to_csv('test_transform.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}