{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "from pyspark.sql.functions import regexp_replace, col, lit, udf"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T11:23:17.415816Z",
     "iopub.execute_input": "2023-03-16T11:23:17.416231Z",
     "iopub.status.idle": "2023-03-16T11:23:17.600439Z",
     "shell.execute_reply.started": "2023-03-16T11:23:17.416192Z",
     "shell.execute_reply": "2023-03-16T11:23:17.598891Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/18 17:47:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('MyApp').getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#test_data = pd.read_csv(\"../datasets/imdb/complete_train.csv\")\n",
    "test_data = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/imdb/complete_train.csv',\n",
    "                                                  header=True, inferSchema=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T11:23:19.329273Z",
     "iopub.execute_input": "2023-03-16T11:23:19.330165Z",
     "iopub.status.idle": "2023-03-16T11:23:19.382437Z",
     "shell.execute_reply.started": "2023-03-16T11:23:19.330115Z",
     "shell.execute_reply": "2023-03-16T11:23:19.381072Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T11:23:19.631015Z",
     "iopub.execute_input": "2023-03-16T11:23:19.631475Z",
     "iopub.status.idle": "2023-03-16T11:23:19.675250Z",
     "shell.execute_reply.started": "2023-03-16T11:23:19.631429Z",
     "shell.execute_reply": "2023-03-16T11:23:19.673746Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[_c0: int, tconst: string, primaryTitle: string, originalTitle: string, startYear: string, endYear: string, runtimeMinutes: string, numVotes: double, label: boolean]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve Plot Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#test_data[\"plot\"] = \"\"\n",
    "test_data = test_data.withColumn(\"plot\", lit(\"\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "start = time.time()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T11:23:24.818064Z",
     "iopub.execute_input": "2023-03-16T11:23:24.819072Z",
     "iopub.status.idle": "2023-03-16T11:23:24.825243Z",
     "shell.execute_reply.started": "2023-03-16T11:23:24.819025Z",
     "shell.execute_reply": "2023-03-16T11:23:24.823492Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "api_calls = 0\n",
    "\n",
    "\"\"\"\n",
    "for index, row in test_data.iterrows():\n",
    "#   if api_calls % 10 == 0:\n",
    "#     print(\"Sleeping for API limit reset.\")\n",
    "#     time.sleep(10)\n",
    "\n",
    "  if api_calls % 10 == 0:\n",
    "    print(f\"Processed {api_calls} sentences.\")\n",
    "\n",
    "  prompt = f\"Give me a roughly 100 words plot of the {row.primaryTitle} from {row.startYear} that has a duration of {row.runtimeMinutes} minutes\"\n",
    "\n",
    "  try:\n",
    "    response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=128,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "    test_data.at[index,'plot'] = response[\"choices\"][0].text\n",
    "    #row[\"answer\"] = response[\"choices\"][0].text\n",
    "    api_calls +=1\n",
    "  except Exception as e:\n",
    "    print(\"Failed on one query. Continuing., \", e)\n",
    "\"\"\"\n",
    "\n",
    "def generate_plot(primaryTitle, startYear, runtimeMinutes):\n",
    "\n",
    "  prompt = f\"Give me a roughly 100 words plot of the {primaryTitle} from {startYear} that has a duration of {runtimeMinutes} minutes\"\n",
    "\n",
    "  try:\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=128,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.5,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response[\"choices\"][0].text\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"Failed on one query. Continuing., \", e)\n",
    "\n",
    "# Generation of the udf\n",
    "udf_generate_plot = udf(generate_plot, StringType())\n",
    "\n",
    "test_data = test_data.withColumn('plot', udf_generate_plot(test_data[\"primaryTitle\"], test_data[\"startYear\"], test_data[\"runtimeMinutes\"]))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T11:23:27.445274Z",
     "iopub.execute_input": "2023-03-16T11:23:27.445766Z",
     "iopub.status.idle": "2023-03-16T12:12:50.164049Z",
     "shell.execute_reply.started": "2023-03-16T11:23:27.445723Z",
     "shell.execute_reply": "2023-03-16T12:12:50.162926Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "end = time.time()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T12:12:50.166508Z",
     "iopub.execute_input": "2023-03-16T12:12:50.166970Z",
     "iopub.status.idle": "2023-03-16T12:12:50.172408Z",
     "shell.execute_reply.started": "2023-03-16T12:12:50.166924Z",
     "shell.execute_reply": "2023-03-16T12:12:50.171270Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "end-start"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T12:12:50.174207Z",
     "iopub.execute_input": "2023-03-16T12:12:50.174926Z",
     "iopub.status.idle": "2023-03-16T12:12:50.188631Z",
     "shell.execute_reply.started": "2023-03-16T12:12:50.174877Z",
     "shell.execute_reply": "2023-03-16T12:12:50.187116Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "80.16172218322754"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[_c0: int, tconst: string, primaryTitle: string, originalTitle: string, startYear: string, endYear: string, runtimeMinutes: string, numVotes: double, label: boolean, plot: string]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#test_data[\"plot\"] = test_data[\"plot\"].replace(r'\\n',' ', regex=True)\n",
    "test_data = test_data.withColumn('plot', regexp_replace(col(\"plot\"), r'\\n', ' '))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T12:17:30.317943Z",
     "iopub.execute_input": "2023-03-16T12:17:30.318392Z",
     "iopub.status.idle": "2023-03-16T12:17:30.329029Z",
     "shell.execute_reply.started": "2023-03-16T12:17:30.318355Z",
     "shell.execute_reply": "2023-03-16T12:17:30.327645Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#test_data.to_csv(\"movies_6000.csv\",index=False)\n",
    "test_data.toPandas().to_csv(\"movies_6000.csv\", index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-16T12:18:04.161726Z",
     "iopub.execute_input": "2023-03-16T12:18:04.162130Z",
     "iopub.status.idle": "2023-03-16T12:18:04.180053Z",
     "shell.execute_reply.started": "2023-03-16T12:18:04.162096Z",
     "shell.execute_reply": "2023-03-16T12:18:04.178532Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.                                           (0 + 1) / 1]\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                                \r"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Awards Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#test_data = pd.read_csv(\"../datasets/gpt_data/validation_plots.csv\")\n",
    "test_data = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/final/validation_plots_awards_genre_no_duplicates.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[Unnamed: 0: int, tconst: string, primaryTitle: string, originalTitle: string, startYear: int, endYear: string, runtimeMinutes: string, numVotes: double, plot: string, awards: int, Genre: string]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data\n",
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "#test_data[\"awards\"] = 0\n",
    "test_data = test_data.withColumn('awards', lit(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "#test_data[\"startYear\"].replace(r\"\\N\", None, inplace=True)\n",
    "#test_data[\"startYear\"].fillna(test_data['endYear'], inplace=True)\n",
    "#test_data[\"startYear\"] = test_data[\"startYear\"].astype(int)\n",
    "\n",
    "test_data = test_data.withColumn('startYear', regexp_replace(col('startYear'), r'\\\\N', None))\n",
    "test_data = test_data.fillna({'startYear': 'endYear'}, subset=['startYear'])\n",
    "#test_data = test_data.select('startYear').fillna(test_data.select('endYear'))\n",
    "test_data = test_data.withColumn('startYear', col('startYear').cast('int'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[Unnamed: 0: int, tconst: string, primaryTitle: string, originalTitle: string, startYear: int, endYear: int, runtimeMinutes: string, numVotes: double, plot: string, awards: int, Genre: string]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "\"\"\"\n",
    "api_calls = 0\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "  prompt = f\"Did the movie {row.primaryTitle if row.primaryTitle is not None else row.originalTitle} from {row.startYear} with a runtime of {row.runtimeMinutes} win any awards? Please only answer with Yes if it won any awards or with No if it did not.\"\n",
    "\n",
    "  try:\n",
    "    response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=32,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "    api_calls +=1\n",
    "\n",
    "    if api_calls % 50 == 0:\n",
    "      print(\"Sleeping for API limit reset.\")\n",
    "      time.sleep(30)\n",
    "\n",
    "    if api_calls % 10 == 0:\n",
    "      print(f\"Processed {api_calls} sentences.\")\n",
    "\n",
    "    test_data.at[index,'awards'] = 1 if \"Yes\" in response[\"choices\"][0].text else 0\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"Failed on one query. Continuing., \", e)\n",
    "    time.sleep(10)\n",
    "\"\"\"\n",
    "\n",
    "def define_awards(primaryTitle, originalTitle, startYear, runtimeMinutes):\n",
    "\n",
    "    prompt = f\"Did the movie {primaryTitle if primaryTitle is not None else originalTitle} from {startYear} with a runtime of {runtimeMinutes} win any awards? Please only answer with Yes if it won any awards or with No if it did not.\"\n",
    "\n",
    "    try:\n",
    "      response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=32,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.5,\n",
    "        presence_penalty=0\n",
    "      )\n",
    "\n",
    "      return 1 if \"Yes\" in response[\"choices\"][0] else 0\n",
    "\n",
    "    except Exception as e:\n",
    "      print(\"Failed on one query. Continuing., \", e)\n",
    "      time.sleep(10)\n",
    "\n",
    "udf_awards = udf(define_awards, IntegerType())\n",
    "\n",
    "test_data = test_data.withColumn('awards', udf_awards(test_data[\"primaryTitle\"], test_data[\"originalTitle\"], test_data[\"startYear\"], test_data[\"runtimeMinutes\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed on one query. Continuing.,  No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/manu/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/manu/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/manu/opt/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [72]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtest_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mawards\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:606\u001B[0m, in \u001B[0;36mDataFrame.show\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    603\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParameter \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be a bool\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(truncate, \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m truncate:\n\u001B[0;32m--> 606\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshowString\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1320\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1313\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m-> 1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1322\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1036\u001B[0m connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_connection()\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1038\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m binary:\n\u001B[1;32m   1040\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection_guard(connection)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py:511\u001B[0m, in \u001B[0;36mClientServerConnection.send_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 511\u001B[0m         answer \u001B[38;5;241m=\u001B[39m smart_decode(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    512\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer received: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(answer))\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001B[39;00m\n\u001B[1;32m    514\u001B[0m         \u001B[38;5;66;03m# answer before the socket raises an error.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "test_data.select(\"awards\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#test_data.to_csv(\"validation_plots_awards.csv\",index=False)\n",
    "\n",
    "test_data.toPandas().fillna(\"validation_plots_awards.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matei\\AppData\\Local\\Temp\\ipykernel_8540\\4224628072.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  test_data.corr()\n"
     ]
    },
    {
     "data": {
      "text/plain": "                _c0  startYear  numVotes     label    awards\n_c0        1.000000   0.884359 -0.042461 -0.191171 -0.077345\nstartYear  0.884359   1.000000  0.007676 -0.246652 -0.069886\nnumVotes  -0.042461   0.007676  1.000000  0.153373  0.336631\nlabel     -0.191171  -0.246652  0.153373  1.000000  0.350620\nawards    -0.077345  -0.069886  0.336631  0.350620  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_c0</th>\n      <th>startYear</th>\n      <th>numVotes</th>\n      <th>label</th>\n      <th>awards</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>_c0</th>\n      <td>1.000000</td>\n      <td>0.884359</td>\n      <td>-0.042461</td>\n      <td>-0.191171</td>\n      <td>-0.077345</td>\n    </tr>\n    <tr>\n      <th>startYear</th>\n      <td>0.884359</td>\n      <td>1.000000</td>\n      <td>0.007676</td>\n      <td>-0.246652</td>\n      <td>-0.069886</td>\n    </tr>\n    <tr>\n      <th>numVotes</th>\n      <td>-0.042461</td>\n      <td>0.007676</td>\n      <td>1.000000</td>\n      <td>0.153373</td>\n      <td>0.336631</td>\n    </tr>\n    <tr>\n      <th>label</th>\n      <td>-0.191171</td>\n      <td>-0.246652</td>\n      <td>0.153373</td>\n      <td>1.000000</td>\n      <td>0.350620</td>\n    </tr>\n    <tr>\n      <th>awards</th>\n      <td>-0.077345</td>\n      <td>-0.069886</td>\n      <td>0.336631</td>\n      <td>0.350620</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Concat all train datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#train_1 = pd.read_csv(\"../datasets/gpt_data/movies_1000.csv\")\n",
    "#train_2 = pd.read_csv(\"../datasets/gpt_data/movies_2000.csv\")\n",
    "#train_3 = pd.read_csv(\"../datasets/gpt_data/movies_3000.csv\")\n",
    "#train_4 = pd.read_csv(\"../datasets/gpt_data/movies_4000.csv\")\n",
    "#train_5 = pd.read_csv(\"../datasets/gpt_data/movies_5000.csv\")\n",
    "#train_6 = pd.read_csv(\"../datasets/gpt_data/movies_6000.csv\")\n",
    "#train_7 = pd.read_csv(\"../datasets/gpt_data/movies_7000.csv\")\n",
    "#train_8 = pd.read_csv(\"../datasets/gpt_data/movies_8000.csv\")\n",
    "\n",
    "train_1 = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/movies_1000.csv', header=True, inferSchema=True)\n",
    "train_2 = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/movies_2000.csv', header=True, inferSchema=True)\n",
    "train_3 = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/movies_3000.csv', header=True, inferSchema=True)\n",
    "train_4 = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/movies_4000.csv', header=True, inferSchema=True)\n",
    "train_5 = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/movies_5000.csv', header=True, inferSchema=True)\n",
    "train_6 = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/movies_6000.csv', header=True, inferSchema=True)\n",
    "train_7 = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/movies_7000.csv', header=True, inferSchema=True)\n",
    "train_8 = spark.read.option(\"escape\", \"\\\"\").csv('../datasets/gpt_data/movies_8000.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "#concat_dataset = pd.concat([train_1, train_2, train_3, train_4, train_5, train_6, train_7, train_8])\n",
    "\n",
    "concat_dataset = train_1.union(train_2).union(train_3).union(train_4).union(train_5).union(train_6).union(train_7).union(train_8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#concat_dataset.to_csv(\"train_movies.csv\", index=False)\n",
    "\n",
    "concat_dataset.toPandas().to_csv(\"train_movies.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Concat awards dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#awards_1 = pd.read_csv(\"../datasets/gpt_data/movies_awards_4000.csv\")\n",
    "#awards_2 = pd.read_csv(\"../datasets/gpt_data/movies_awards_6000.csv\")\n",
    "#awards_3 = pd.read_csv(\"../datasets/gpt_data/movies_awards_8000.csv\")\n",
    "\n",
    "awards_1 = spark.read.option(\"escape\", \"\\\"\").csv(\"../datasets/gpt_data/movies_awards_4000.csv\", header=True, inferSchema=True)\n",
    "awards_2 = spark.read.option(\"escape\", \"\\\"\").csv(\"../datasets/gpt_data/movies_awards_6000.csv\", header=True, inferSchema=True)\n",
    "awards_3 = spark.read.option(\"escape\", \"\\\"\").csv(\"../datasets/gpt_data/movies_awards_8000.csv\", header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "#awards_concat = pd.concat([awards_1, awards_2, awards_3])\n",
    "\n",
    "awards_concat = awards_1.union(awards_2).union(awards_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[_c0: int, tconst: string, primaryTitle: string, originalTitle: string, startYear: int, endYear: string, runtimeMinutes: string, numVotes: double, label: boolean, plot: string, awards: int]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards_concat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "corr() missing 2 required positional arguments: 'col1' and 'col2'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [78]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mawards_concat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorr\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: corr() missing 2 required positional arguments: 'col1' and 'col2'"
     ]
    }
   ],
   "source": [
    "awards_concat.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#awards_concat.to_csv(\"train_plot_awards.csv\", index=False)\n",
    "\n",
    "awards_concat.toPandas().to_csv(\"train_plot_awards.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}